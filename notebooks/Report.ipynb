{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipankarsrirag/Dialogue-Summarisation/blob/main/notebooks/Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWemnrRfBIXo",
        "outputId": "1971593c-8d36-4dc3-b565-a68c40f5c708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from io import open\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "MAX_LENGTH = 200\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6O_O1498B59n"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, embedding_matrix=None, bidirectional=True, freeze = True, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_directions = 2\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=freeze, padding_idx=PAD_IDX)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(\n",
        "                input_size, hidden_size, padding_idx=PAD_IDX)\n",
        "\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers,\n",
        "                          batch_first=True, bidirectional=self.bidirectional)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            batch, seq_len, _ = output.shape\n",
        "            output = output.view(\n",
        "                (batch, seq_len, self.num_directions, self.hidden_size))\n",
        "\n",
        "            hidden = hidden.view(\n",
        "                self.num_layers, self.num_directions, batch, self.hidden_size)\n",
        "            output = output[:, :, 0, :]+output[:, :, 1, :]\n",
        "            hidden = hidden[:, 0, :, :] + hidden[0, 1, :, :]\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers, embedding_matrix=None, freeze = True, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=freeze, padding_idx=PAD_IDX)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(\n",
        "                output_size, hidden_size, padding_idx=PAD_IDX)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size,\n",
        "                          num_layers, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(\n",
        "            batch_size, 1, dtype=torch.long, device=device).fill_(SOS_TOKEN)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None and i < target_tensor.size(1):\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        last_layer_hidden = hidden[-1].unsqueeze(0)\n",
        "        query = last_layer_hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CWewwreCvx1b"
      },
      "outputs": [],
      "source": [
        "def fix_contractions(text):\n",
        "    with open('/content/drive/My Drive/COMP9444/data/contractions.json', 'r') as f:\n",
        "        contractions = json.load(f)\n",
        "    tokens = text.split()\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        cleaned.append(contractions.get(token, token))\n",
        "    return ' '.join(cleaned)\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    tokenizer = WordPunctTokenizer()\n",
        "    text = fix_contractions(text)\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    text = ' '.join(tokens).lower()\n",
        "    text = text.replace('# person1 #', '#person1#')\n",
        "    text = text.replace('# person2 #', '#person2#')\n",
        "    text = text.replace('# person3 #', '#person3#')\n",
        "    text = text.replace('# person4 #', '#person4#')\n",
        "    text = text.replace('# person5 #', '#person5#')\n",
        "    text = text.replace('# person6 #', '#person6#')\n",
        "    text = text.replace('# person7 #', '#person7#')\n",
        "    text = text.replace(' ,', ',')\n",
        "    text = text.replace(' .', '.')\n",
        "    text = text.replace(' ?', '?')\n",
        "    text = text.replace(' !', '!')\n",
        "    text = text.replace(\" ' \", \"'\")\n",
        "    text = text.replace(\"< \", \"<\")\n",
        "    text = text.replace(\" >\", \">\")\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def prepareData(src, trg):\n",
        "    dial = np.array(src)\n",
        "    summary = np.array(trg)\n",
        "    pairs = [[dial[i], summary[i]] for i in range(len(dial))]\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def indexesFromSentence(sentence):\n",
        "    return [dictionary.get(word) for word in tokenize(sentence) if word in dictionary.keys()]\n",
        "\n",
        "\n",
        "def tensorFromSentence(sentence):\n",
        "    indexes = indexesFromSentence(sentence)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(pair[0])\n",
        "    target_tensor = tensorFromSentence(pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "\n",
        "def get_dataloader(pairs, batch_size):\n",
        "\n",
        "    num_pairs = len(pairs)\n",
        "\n",
        "    input_ids = np.full((num_pairs, MAX_LENGTH), PAD_IDX, dtype=np.int32)\n",
        "    target_ids = np.full((num_pairs, MAX_LENGTH), PAD_IDX, dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(inp)\n",
        "        tgt_ids = indexesFromSentence(tgt)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids[:MAX_LENGTH]\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids[:MAX_LENGTH]\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return train_dataloader\n",
        "\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "                decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(\n",
        "            encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def validate_epoch(dataloader, encoder, decoder, criterion):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            input_tensor, target_tensor = data\n",
        "\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            loss = criterion(\n",
        "                decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "                target_tensor.view(-1)\n",
        "            )\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uP7le4_lEom5"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001):\n",
        "\n",
        "    # Using Adam with momentum\n",
        "    model_type = \"Final\" if encoder.bidirectional else \"Lite\"\n",
        "    encoder_optimizer = optim.Adam(\n",
        "        encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(\n",
        "        decoder.parameters(), lr=learning_rate)\n",
        "    scheduler_encoder = optim.lr_scheduler.StepLR(\n",
        "        encoder_optimizer, step_size=10, gamma=0.5)\n",
        "    scheduler_decoder = optim.lr_scheduler.StepLR(\n",
        "        decoder_optimizer, step_size=10, gamma=0.5)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
        "        train_loss = train_epoch(train_dataloader, encoder, decoder,\n",
        "                           encoder_optimizer, decoder_optimizer, criterion)\n",
        "        val_loss = validate_epoch(val_dataloader, encoder, decoder, criterion)\n",
        "\n",
        "        scheduler_encoder.step()\n",
        "        scheduler_decoder.step()\n",
        "\n",
        "        print(f'Epoch {epoch}, Train Loss: {train_loss}, Validation Loss: {val_loss}')\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(encoder.state_dict(), f'/content/drive/My Drive/COMP9444/models/Custom-{model_type}/encoder_best.pth')\n",
        "            torch.save(decoder.state_dict(), f'/content/drive/My Drive/COMP9444/models/Custom-{model_type}/decoder_best.pth')\n",
        "\n",
        "        early_stopping(val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "\n",
        "def evaluate(encoder, decoder, sentence):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(\n",
        "            encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_TOKEN:\n",
        "                decoded_words.append('<eos>')\n",
        "                break\n",
        "            decoded_words.append(vocab[idx.item()])\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RUdVDa01BIXr"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_json('/content/drive/My Drive/COMP9444/data/raw/dialogsum/dialogsum.train.jsonl',\n",
        "                      lines=True)[['dialogue', 'summary']]\n",
        "dev_df = pd.read_json('/content/drive/My Drive/COMP9444/data/raw/dialogsum/dialogsum.dev.jsonl',\n",
        "                      lines=True)[['dialogue', 'summary']]\n",
        "\n",
        "train_src_tokens = list(train_df['dialogue'].apply(lambda x: tokenize(x)))\n",
        "train_trg_tokens = list(train_df['summary'].apply(lambda x: tokenize(x)))\n",
        "\n",
        "dev_src_tokens = list(dev_df['dialogue'].apply(lambda x: tokenize(x)))\n",
        "dev_trg_tokens = list(dev_df['summary'].apply(lambda x: tokenize(x)))\n",
        "\n",
        "train_src = [' '.join(sent) for sent in train_src_tokens]\n",
        "train_trg = [' '.join(sent) for sent in train_trg_tokens]\n",
        "\n",
        "dev_src = [' '.join(sent) for sent in dev_src_tokens]\n",
        "dev_trg = [' '.join(sent) for sent in dev_trg_tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ei-Gwx8DBIXs"
      },
      "outputs": [],
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format(\n",
        "        '/content/drive/My Drive/COMP9444/models/GloVe-Word2Vec/glove.bin')\n",
        "\n",
        "pad_token = \"<pad>\"\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "if pad_token not in word_vectors.key_to_index:\n",
        "    pad_index = len(word_vectors)\n",
        "    word_vectors.key_to_index[pad_token] = pad_index\n",
        "    word_vectors.index_to_key.append(pad_token)\n",
        "else:\n",
        "    pad_index = word_vectors.key_to_index[pad_token]\n",
        "\n",
        "PAD_IDX = pad_index\n",
        "SOS_TOKEN = word_vectors.key_to_index['<sos>']\n",
        "EOS_TOKEN = word_vectors.key_to_index['<eos>']\n",
        "\n",
        "vocab = list(word_vectors.key_to_index.keys())\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = word_vectors.get_vector('<sos>').shape[0]\n",
        "dictionary = word_vectors.key_to_index\n",
        "\n",
        "embedding_matrix = torch.zeros(vocab_size, embedding_dim)\n",
        "\n",
        "for i, word in enumerate(vocab):\n",
        "    if word == pad_token:\n",
        "        continue\n",
        "    embedding_matrix[i] = torch.Tensor(np.array(word_vectors[word]))\n",
        "embedding_matrix = embedding_matrix.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4rcrj3A0KCQU"
      },
      "outputs": [],
      "source": [
        "hidden_size = 300\n",
        "batch_size = 32\n",
        "num_layers = 3\n",
        "\n",
        "train_pairs = prepareData(train_src, train_trg)\n",
        "val_pairs = prepareData(dev_src, dev_trg)\n",
        "\n",
        "train_dataloader = get_dataloader(train_pairs, batch_size)\n",
        "val_dataloader = get_dataloader(val_pairs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8Uwa3nJ5KX_U"
      },
      "outputs": [],
      "source": [
        "encoder_lite = EncoderRNN(input_size=vocab_size, hidden_size=hidden_size, num_layers=1, embedding_matrix=embedding_matrix, bidirectional=False).to(device)\n",
        "decoder_lite = AttnDecoderRNN(hidden_size=hidden_size, output_size=vocab_size, num_layers=1, embedding_matrix=embedding_matrix).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnewr7AcK66r",
        "outputId": "ebd62917-21c1-4b7c-a530-651918a94003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters for Custom-Lite: 3433209\n"
          ]
        }
      ],
      "source": [
        "total_params_encoder = count_trainable_parameters(encoder_lite)\n",
        "total_params_decoder = count_trainable_parameters(decoder_lite)\n",
        "total_params_attention = count_trainable_parameters(decoder_lite.attention)\n",
        "\n",
        "total_trainable_params = total_params_encoder + \\\n",
        "        total_params_decoder+total_params_attention\n",
        "print(f'Total trainable parameters for Custom-Lite: {total_trainable_params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rLNI6ftqLLDM"
      },
      "outputs": [],
      "source": [
        "encoder_final = EncoderRNN(input_size=vocab_size, hidden_size=hidden_size, num_layers=num_layers, embedding_matrix=embedding_matrix, bidirectional=True, freeze=False).to(device)\n",
        "decoder_final = AttnDecoderRNN(hidden_size=hidden_size, output_size=vocab_size, num_layers=num_layers, embedding_matrix=embedding_matrix, freeze=False).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAU1lWGnLbl6",
        "outputId": "887d6359-ae55-43c8-dd81-45d5542977eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters for Custom-Final: 8305809\n"
          ]
        }
      ],
      "source": [
        "total_params_encoder = count_trainable_parameters(encoder_final)\n",
        "total_params_decoder = count_trainable_parameters(decoder_final)\n",
        "total_params_attention = count_trainable_parameters(decoder_final.attention)\n",
        "\n",
        "total_trainable_params = total_params_encoder + \\\n",
        "        total_params_decoder+total_params_attention\n",
        "print(f'Total trainable parameters for Custom-Final: {total_trainable_params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "e263552b0139426cacf7a743ff35fade",
            "74d38154ac704d5991bee176557e579b",
            "baf209dc5401432a8ae23fe0d301cce2",
            "0459c6f9754e4cf6b0ac9ab176c61530",
            "924bcf2ed38f4d0c929cb4486e0dc685",
            "04c1878deb0641978ea0a859a8302274",
            "ac7776bee24948bd83d2329c86cca673",
            "1dc4d841112b4eb9a9fa511e3fb8fb1d",
            "a58102ea9f714238b2c59380232934cf",
            "ded20b006f8449bcbd13b6d9d4118793",
            "1500bc443f984e6ab5258affe30372ec"
          ]
        },
        "id": "uMqEBvJQLeMc",
        "outputId": "9108641e-f5e9-404b-bcb1-78014b90d9f7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e263552b0139426cacf7a743ff35fade",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 4.9933965841929115, Validation Loss: 4.366142988204956\n",
            "Epoch 2, Train Loss: 4.205470601106302, Validation Loss: 4.029539257287979\n",
            "Epoch 3, Train Loss: 3.8132927002050936, Validation Loss: 3.818986564874649\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bf00024284a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_lite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_lite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-ba645f380f69>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         train_loss = train_epoch(train_dataloader, encoder, decoder,\n\u001b[0m\u001b[1;32m     20\u001b[0m                            encoder_optimizer, decoder_optimizer, criterion)\n\u001b[1;32m     21\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-4f934f48d43a>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         )\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(train_dataloader, val_dataloader, encoder_lite, decoder_lite, 10, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX_BBh55NxkB"
      },
      "outputs": [],
      "source": [
        "train(train_dataloader, val_dataloader, encoder_final, decoder_final, 10, 0.001)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0459c6f9754e4cf6b0ac9ab176c61530": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ded20b006f8449bcbd13b6d9d4118793",
            "placeholder": "​",
            "style": "IPY_MODEL_1500bc443f984e6ab5258affe30372ec",
            "value": " 3/10 [07:22&lt;16:42, 143.24s/it]"
          }
        },
        "04c1878deb0641978ea0a859a8302274": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1500bc443f984e6ab5258affe30372ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dc4d841112b4eb9a9fa511e3fb8fb1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d38154ac704d5991bee176557e579b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c1878deb0641978ea0a859a8302274",
            "placeholder": "​",
            "style": "IPY_MODEL_ac7776bee24948bd83d2329c86cca673",
            "value": " 30%"
          }
        },
        "924bcf2ed38f4d0c929cb4486e0dc685": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a58102ea9f714238b2c59380232934cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac7776bee24948bd83d2329c86cca673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf209dc5401432a8ae23fe0d301cce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc4d841112b4eb9a9fa511e3fb8fb1d",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a58102ea9f714238b2c59380232934cf",
            "value": 3
          }
        },
        "ded20b006f8449bcbd13b6d9d4118793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e263552b0139426cacf7a743ff35fade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74d38154ac704d5991bee176557e579b",
              "IPY_MODEL_baf209dc5401432a8ae23fe0d301cce2",
              "IPY_MODEL_0459c6f9754e4cf6b0ac9ab176c61530"
            ],
            "layout": "IPY_MODEL_924bcf2ed38f4d0c929cb4486e0dc685"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
