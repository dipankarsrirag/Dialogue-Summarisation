{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('knkarthick/dialogsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/BART'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task= 'summarization', model=model, tokenizer= tokenizer, device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"#Person1#: Excuse me, how can I get special discount coupons?\\n#Person2#: Buy more and get more special discount coupons.\\n#Person1#: Can I get a discount coupon if I buy these goods?\\n#Person2#: Of course You get a coupon for every 3 bags of sugar.\\n#Person1#: But how much discount can I get if I use it to buy goods next time?\\n#Person2#: 10 pence off if you use this coupon.\\n#Person1#: Can I buy everything in the supermarket by it? .\\n#Person2#: Yeah, you need to take advantage of it within its expiry date.\\n#Person1#: How long can I keep it?\\n#Person2#: The coupon can be used at least one year.\\n#Person1#: I see. I will take 9 bags of sugar so that I can get 3 coupons.\\n#Person2#: All right. I will get them for you.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {'length_penalty': 0.7, 'num_beams': 8, \"max_length\": 120, 'min_length':30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2# tells #Person1# how to get special discount coupons and how to use it to buy goods next time. They will take 9 bags of sugar.\n"
     ]
    }
   ],
   "source": [
    "summary = pipe(text, **gen_kwargs)[0]['summary_text'].split()\n",
    "print(' '.join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "refer = [\"#Person2# answers #Person1#'s questions about getting special discount coupons and how to use them.\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5661143599740092\n"
     ]
    }
   ],
   "source": [
    "score = meteor_score(refer, summary)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Excuse me, how can I get special discount coupons?\n",
      "#Person2#: Buy more and get more special discount coupons.\n",
      "#Person1#: Can I get a discount coupon if I buy these goods?\n",
      "#Person2#: Of course You get a coupon for every 3 bags of sugar.\n",
      "#Person1#: But how much discount can I get if I use it to buy goods next time?\n",
      "#Person2#: 10 pence off if you use this coupon.\n",
      "#Person1#: Can I buy everything in the supermarket by it? .\n",
      "#Person2#: Yeah, you need to take advantage of it within its expiry date.\n",
      "#Person1#: How long can I keep it?\n",
      "#Person2#: The coupon can be used at least one year.\n",
      "#Person1#: I see. I will take 9 bags of sugar so that I can get 3 coupons.\n",
      "#Person2#: All right. I will get them for you.\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased = \"\"\"\n",
    "#person1#: what seems to be the problem? #person2#: my stomach hurts, doctor. #person1#: has this been a problem before? #person2#: yes. #person1#: for how long? #person2#: i have had it on and off for the past three years. it's just gotten much worse these past two weeks. #person1#: do you only feel this way when you stomach is empty? #person2#: after i have eaten, it goes away for a while. #person1#: do you feel nauseous? #person2#: yes, occasionally. #person1#: do you have regular bowel movements? #person2#: i think so. #person1#: let me take a look at your abdomen. lie down on your back and bend your knees up. ok. relax... alright, it seems like you have a duodenal ulcer, but we will have to run some tests before i can be certain. you should get a good rest first and try not to strain your stomach too much. #person2#: is it serious? #person1#: not too serious, but it will take you some time to recover, so you will need to be patient\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#person1#: what seems to be the problem? #person2#: my stomach hurts, doctor. #person1#: has this been a problem before? #person2#: yes. #person1#: for how long? #person2#: i have had it on and off for the past three years. it's just gotten much worse these past two weeks. #person1#: do you only feel this way when you stomach is empty? #person2#: after i have eaten, it goes away for a while. #person1#: do you feel nauseous? #person2#: yes, occasionally. #person1#: do you have regular bowel movements? #person2#: i think so. #person1#: let me take a look at your abdomen. lie down on your back and bend your knees up. ok. relax... alright, it seems like you have a duodenal ulcer, but we will have to run some tests before i can be certain. you should get a good rest first and try not to strain your stomach too much. #person2#: is it serious? #person1#: not too serious, but it will take you some time to recover, so you will need to be patient\n",
      "\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "print(biased)\n",
    "print(len(biased.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#person2#'s stomach hurts and #person1# tells #person3# it's because of a duodenal ulcer.\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "summary = pipe(biased, **gen_kwargs)[0]['summary_text']\n",
    "print(summary)\n",
    "print(len(summary.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
