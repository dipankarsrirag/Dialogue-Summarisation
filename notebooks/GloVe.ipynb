{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import contractions\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file_path):\n",
    "    glove_model = KeyedVectors.load_word2vec_format(glove_file_path, binary=False, no_header=True)\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('../data/raw/dialogsum/dialogsum.train.jsonl', lines = True)[['dialogue', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = contractions.fix(text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        clean_tokens.append(token)\n",
    "    text = ' '.join(clean_tokens).lower()\n",
    "    text = text.replace('# person1 #', '#person1#')\n",
    "    text = text.replace('# person2 #', '#person2#')\n",
    "    text = text.replace('# person3 #', '#person3#')\n",
    "    text = text.replace('# person4 #', '#person4#')\n",
    "    text = text.replace('# person5 #', '#person5#')\n",
    "    text = text.replace('# person6 #', '#person6#')\n",
    "    text = text.replace('# person7 #', '#person7#')\n",
    "    text = text.replace(' ,', ',')\n",
    "    text = text.replace(' .', '.')\n",
    "    text = text.replace(' ?', '?')\n",
    "    text = text.replace(' !', '!')\n",
    "    text = text.replace(\" ' \", \"'\")\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([train['dialogue'], train['summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(concat.apply(lambda x : tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Word2Vec(vector_size=300, min_count = 20, epochs=20)\n",
    "base_model.build_vocab(tokens)\n",
    "total_examples = base_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name?', 0.20081743597984314),\n",
       " ('pale.', 0.1952628791332245),\n",
       " ('francisco', 0.1833544671535492),\n",
       " ('flu.', 0.1742691844701767),\n",
       " ('duties', 0.17293964326381683),\n",
       " ('won', 0.1703324317932129),\n",
       " ('mom.', 0.16947486996650696),\n",
       " ('university.', 0.16828463971614838),\n",
       " ('drama', 0.16771653294563293),\n",
       " ('early.', 0.16720540821552277)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.wv.most_similar('#person1#', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '../embeds/GloVe/glove.corpus.300d.txt'\n",
    "corpus_model = load_glove_model(corpus_path)\n",
    "base_model.build_vocab([list(corpus_model.key_to_index.keys())], update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tells', 0.6852829456329346),\n",
       " ('asks', 0.6342537999153137),\n",
       " ('suggests', 0.5803223848342896),\n",
       " ('#person2#', 0.5709367394447327),\n",
       " ('recommends', 0.5490970015525818),\n",
       " ('thinks', 0.538934588432312),\n",
       " ('advises', 0.530464768409729),\n",
       " ('#person1#.', 0.5236577391624451),\n",
       " ('complains', 0.5215713977813721),\n",
       " ('wants', 0.5100038051605225)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_model.most_similar('#person1#', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.train(tokens, total_examples=total_examples, epochs=base_model.epochs)\n",
    "base_model_wv = base_model.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#person2#', 0.8051125407218933),\n",
       " ('#person3#', 0.5365425944328308),\n",
       " ('sam', 0.5109261870384216),\n",
       " ('jeff', 0.4995196461677551),\n",
       " ('#person2#.', 0.4818013310432434),\n",
       " ('amy', 0.47963079810142517),\n",
       " ('#person2#,', 0.4759983420372009),\n",
       " ('#person1#.', 0.4756500720977783),\n",
       " ('#person1#,', 0.47492074966430664),\n",
       " ('chris', 0.4728524088859558)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_wv.most_similar('#person1#', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_wv.save_word2vec_format('../models/GloVe-Word2Vec/glove.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
